{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1.  How do you install and verify that TensorFlow 2.0 was installed successfully\n",
        "\n",
        "pip install tensorflow==2.0.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check basic operation\n",
        "hello = tf.constant('Hello, TensorFlow 2.0!')\n",
        "print(hello.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "moojb31ht4pJ",
        "outputId": "227fdaca-174a-4030-8f96-5dc58fb329de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-1-1342184515.py, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1-1342184515.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    pip install tensorflow==2.0.0\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. How can you define a simple function in TensorFlow 2.0 to perform addition\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def add_numbers(x, y):\n",
        "    return tf.add(x, y)\n",
        "\n",
        "# Example\n",
        "a = tf.constant(5)\n",
        "b = tf.constant(3)\n",
        "result = add_numbers(a, b)\n",
        "print(\"Result:\", result.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNENDnsft4lv",
        "outputId": "f385fc74-183a-4a8c-f275-a71522b2053f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.  How can you create a simple neural network in TensorFlow 2.0 with one hidden layer\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the model\n",
        "model = models.Sequential([\n",
        "    layers.Dense(16, activation='relu', input_shape=(4,)),   # Hidden layer with 16 neurons\n",
        "    layers.Dense(1, activation='sigmoid')                    # Output layer for binary classification\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9vJVPoyt4jt",
        "outputId": "5eb3bffa-2ddb-4617-d7c7-07d120e05a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.  How can you visualize the training progress using TensorFlow and Matplotlib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "\n",
        "# Create dummy data\n",
        "X_train = np.random.rand(100, 4)\n",
        "y_train = np.random.randint(0, 2, size=(100, 1))\n",
        "\n",
        "# Build a simple model\n",
        "model = models.Sequential([\n",
        "    layers.Dense(16, activation='relu', input_shape=(4,)),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train and save history\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=8, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBqBt9ldt4hB",
        "outputId": "e2cb743c-348d-45ec-e51a-2cac800ba2c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4254 - loss: 0.6955 - val_accuracy: 0.3000 - val_loss: 0.7153\n",
            "Epoch 2/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4909 - loss: 0.6914 - val_accuracy: 0.3500 - val_loss: 0.7142\n",
            "Epoch 3/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5285 - loss: 0.6907 - val_accuracy: 0.3500 - val_loss: 0.7135\n",
            "Epoch 4/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5449 - loss: 0.6911 - val_accuracy: 0.3500 - val_loss: 0.7121\n",
            "Epoch 5/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5930 - loss: 0.6859 - val_accuracy: 0.4000 - val_loss: 0.7114\n",
            "Epoch 6/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4793 - loss: 0.7000 - val_accuracy: 0.3500 - val_loss: 0.7108\n",
            "Epoch 7/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5648 - loss: 0.6878 - val_accuracy: 0.4000 - val_loss: 0.7098\n",
            "Epoch 8/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5522 - loss: 0.6911 - val_accuracy: 0.3500 - val_loss: 0.7090\n",
            "Epoch 9/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4033 - loss: 0.7061 - val_accuracy: 0.4000 - val_loss: 0.7085\n",
            "Epoch 10/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5388 - loss: 0.6903 - val_accuracy: 0.4000 - val_loss: 0.7077\n",
            "Epoch 11/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5939 - loss: 0.6844 - val_accuracy: 0.4000 - val_loss: 0.7072\n",
            "Epoch 12/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5295 - loss: 0.6924 - val_accuracy: 0.4000 - val_loss: 0.7067\n",
            "Epoch 13/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6909 - val_accuracy: 0.4500 - val_loss: 0.7061\n",
            "Epoch 14/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4938 - loss: 0.6974 - val_accuracy: 0.4500 - val_loss: 0.7056\n",
            "Epoch 15/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5089 - loss: 0.6936 - val_accuracy: 0.4500 - val_loss: 0.7050\n",
            "Epoch 16/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5275 - loss: 0.6926 - val_accuracy: 0.4500 - val_loss: 0.7044\n",
            "Epoch 17/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5340 - loss: 0.6900 - val_accuracy: 0.4500 - val_loss: 0.7040\n",
            "Epoch 18/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5499 - loss: 0.6897 - val_accuracy: 0.5000 - val_loss: 0.7035\n",
            "Epoch 19/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6522 - loss: 0.6777 - val_accuracy: 0.5000 - val_loss: 0.7031\n",
            "Epoch 20/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5828 - loss: 0.6884 - val_accuracy: 0.5000 - val_loss: 0.7028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. How do you install PyTorch and verify the PyTorch installation\n",
        "\n",
        "pip install torch torchvision torchaudio\n",
        "import torch\n",
        "\n",
        "# Check PyTorch version\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "\n",
        "# Check if CUDA (GPU) is available\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n",
        "# If using GPU, print device name\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU device:\", torch.cuda.get_device_name(0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "eqg3PsTxvBe0",
        "outputId": "c68472da-0d8e-49b0-9dea-57e83cd2aeca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-5-4184440055.py, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-5-4184440055.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    pip install torch torchvision torchaudio\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. How do you create a simple neural network in PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.hidden = nn.Linear(4, 16)      # Input layer to hidden layer\n",
        "        self.relu = nn.ReLU()\n",
        "        self.output = nn.Linear(16, 1)      # Hidden layer to output layer\n",
        "        self.sigmoid = nn.Sigmoid()         # For binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.output(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "model = SimpleNN()\n",
        "criterion = nn.BCELoss()                  # Binary Cross-Entropy for binary classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "# 100 samples, 4 features each\n",
        "X = torch.rand(100, 4)\n",
        "y = torch.randint(0, 2, (100, 1)).float()\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X)\n",
        "    loss = criterion(outputs, y)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "with torch.no_grad():\n",
        "    predictions = model(X)\n",
        "    predicted_labels = (predictions > 0.5).float()\n",
        "    print(predicted_labels[:10])  # Show first 10 predictions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4j7sRf6vBY8",
        "outputId": "2aa1b561-380c-4028-e085-5a91e39f0397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 0.6974\n",
            "Epoch [2/20], Loss: 0.6929\n",
            "Epoch [3/20], Loss: 0.6894\n",
            "Epoch [4/20], Loss: 0.6871\n",
            "Epoch [5/20], Loss: 0.6859\n",
            "Epoch [6/20], Loss: 0.6856\n",
            "Epoch [7/20], Loss: 0.6854\n",
            "Epoch [8/20], Loss: 0.6851\n",
            "Epoch [9/20], Loss: 0.6846\n",
            "Epoch [10/20], Loss: 0.6838\n",
            "Epoch [11/20], Loss: 0.6828\n",
            "Epoch [12/20], Loss: 0.6818\n",
            "Epoch [13/20], Loss: 0.6809\n",
            "Epoch [14/20], Loss: 0.6801\n",
            "Epoch [15/20], Loss: 0.6794\n",
            "Epoch [16/20], Loss: 0.6787\n",
            "Epoch [17/20], Loss: 0.6781\n",
            "Epoch [18/20], Loss: 0.6774\n",
            "Epoch [19/20], Loss: 0.6767\n",
            "Epoch [20/20], Loss: 0.6761\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. How do you define a loss function and optimizer in PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# 1. Define a simple neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.hidden = nn.Linear(4, 16)\n",
        "        self.output = nn.Linear(16, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.hidden(x))\n",
        "        x = self.sigmoid(self.output(x))\n",
        "        return x\n",
        "\n",
        "# 2. Instantiate model, loss function, and optimizer\n",
        "model = SimpleNN()\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# 3. Generate dummy data\n",
        "X = torch.rand(100, 4)                      # 100 samples, 4 features\n",
        "y = torch.randint(0, 2, (100, 1)).float()   # Binary targets (0 or 1)\n",
        "\n",
        "# 4. Training loop\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X)\n",
        "    loss = criterion(outputs, y)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# 5. Test prediction\n",
        "with torch.no_grad():\n",
        "    predictions = model(X)\n",
        "    predicted_labels = (predictions > 0.5).float()\n",
        "    print(\"\\nSample Predictions:\")\n",
        "    print(predicted_labels[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3mby8h1vBW-",
        "outputId": "d4465cde-7737-41c0-f1c2-9732c18c334d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.6911\n",
            "Epoch 2/20, Loss: 0.6902\n",
            "Epoch 3/20, Loss: 0.6892\n",
            "Epoch 4/20, Loss: 0.6883\n",
            "Epoch 5/20, Loss: 0.6874\n",
            "Epoch 6/20, Loss: 0.6866\n",
            "Epoch 7/20, Loss: 0.6858\n",
            "Epoch 8/20, Loss: 0.6850\n",
            "Epoch 9/20, Loss: 0.6842\n",
            "Epoch 10/20, Loss: 0.6834\n",
            "Epoch 11/20, Loss: 0.6825\n",
            "Epoch 12/20, Loss: 0.6817\n",
            "Epoch 13/20, Loss: 0.6809\n",
            "Epoch 14/20, Loss: 0.6801\n",
            "Epoch 15/20, Loss: 0.6792\n",
            "Epoch 16/20, Loss: 0.6783\n",
            "Epoch 17/20, Loss: 0.6775\n",
            "Epoch 18/20, Loss: 0.6766\n",
            "Epoch 19/20, Loss: 0.6756\n",
            "Epoch 20/20, Loss: 0.6748\n",
            "\n",
            "Sample Predictions:\n",
            "tensor([[1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. How do you implement a custom loss function in PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Dummy model\n",
        "model = nn.Linear(4, 1)\n",
        "\n",
        "# Custom loss function\n",
        "class CustomMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomMSELoss, self).__init__()\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        return torch.mean((output - target) ** 2)\n",
        "\n",
        "# Instantiate loss and optimizer\n",
        "criterion = CustomMSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Dummy data\n",
        "X = torch.rand(10, 4)\n",
        "y = torch.rand(10, 1)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(5):\n",
        "    outputs = model(X)\n",
        "    loss = criterion(outputs, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP0_RJZPvBUv",
        "outputId": "8a8d4c4e-7f15-4a93-8e66-068a8ae339b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.2084\n",
            "Epoch 2, Loss: 0.2017\n",
            "Epoch 3, Loss: 0.1955\n",
            "Epoch 4, Loss: 0.1897\n",
            "Epoch 5, Loss: 0.1843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. How do you save and load a TensorFlow mode\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Define and compile the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(16, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # for binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 2: Create dummy training data\n",
        "X_train = np.random.rand(100, 4)  # 100 samples, 4 features\n",
        "y_train = np.random.randint(0, 2, (100, 1))  # binary targets (0 or 1)\n",
        "\n",
        "# Step 3: Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=10)\n",
        "\n",
        "# Step 4: Save the model (SavedModel format)\n",
        "model.save(\"my_model\")  # creates 'my_model/' directory\n",
        "\n",
        "# Step 5: Save the model (HDF5 format)\n",
        "model.save(\"my_model.h5\")  # creates a single HDF5 file\n",
        "\n",
        "# Step 6: Load the SavedModel format\n",
        "loaded_model_1 = tf.keras.models.load_model(\"my_model\")\n",
        "print(\"\\n✅ Loaded from SavedModel:\")\n",
        "loaded_model_1.summary()\n",
        "\n",
        "# Step 7: Load the HDF5 format\n",
        "loaded_model_2 = tf.keras.models.load_model(\"my_model.h5\")\n",
        "print(\"\\n✅ Loaded from HDF5:\")\n",
        "loaded_model_2.summary()\n",
        "\n",
        "# Step 8: Make predictions with loaded models\n",
        "sample_input = np.random.rand(1, 4)\n",
        "prediction_1 = loaded_model_1.predict(sample_input)\n",
        "prediction_2 = loaded_model_2.predict(sample_input)\n",
        "\n",
        "print(\"\\nPrediction from SavedModel:\", prediction_1)\n",
        "print(\"Prediction from HDF5 model:\", prediction_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "H5ugLt-uvBSE",
        "outputId": "5412049c-81c3-4335-ee7d-49a3dde66b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4116 - loss: 0.7073\n",
            "Epoch 2/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4103 - loss: 0.7064 \n",
            "Epoch 3/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4402 - loss: 0.6989 \n",
            "Epoch 4/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3884 - loss: 0.7034 \n",
            "Epoch 5/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3407 - loss: 0.7101 \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=my_model.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-9-3986513038.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Step 4: Save the model (SavedModel format)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_model\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# creates 'my_model/' directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Step 5: Save the model (HDF5 format)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         )\n\u001b[0;32m--> 114\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;34m\"Invalid filepath extension for saving. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;34m\"Please add either a `.keras` extension for the native Keras \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=my_model."
          ]
        }
      ]
    }
  ]
}